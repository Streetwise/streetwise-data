{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning and augmentation\n",
    "\n",
    "Preprocessing of dataset containing images from google streetview.\n",
    "First delete all the images with no content and remove those from the .csv dataset.\n",
    "Then do some data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import itertools\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read list of all files in the dicectory to be cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50f5ed9afdc9f065f0008e32.jpg\n"
     ]
    }
   ],
   "source": [
    "filesList = os.listdir(\"imagesgoogle_cleaned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "Compare each image to the template (containing \"Sorry, we have no imagery here\") and delete all the images with the same content (the norm between those and the template are -> 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Except: .DS_S\n",
      "Except: .ipynb_checkpo\n",
      "Deleted 0 images\n"
     ]
    }
   ],
   "source": [
    "template = cv2.imread(\"template.jpg\")\n",
    "deletedcount = 0\n",
    "\n",
    "for fn in filesList:\n",
    "    img = cv2.imread(\"imagesgoogle_cleaned/\"+fn)\n",
    "    try:\n",
    "        if cv2.norm(template, img)< 10:\n",
    "            print(fn)\n",
    "            os.remove(\"imagesgoogle_cleaned/\"+fn)\n",
    "            deletedcount+=1\n",
    "    except:\n",
    "        print(\"Except: \"+fn)\n",
    "        pass\n",
    "        \n",
    "print(\"Deleted \"+str(deletedcount)+\" images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update csv file containing comparisons to get rid of comparison with deleted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "filesList = [f[:-4] for f in os.listdir(\"imagesgoogle_cleaned\")]\n",
    "\n",
    "# Read csv file and remove lines containing deleted images\n",
    "with open(\"data/imagesgoogle.csv\") as csv_file:\n",
    "    newData = [row for row in csv.reader(csv_file) if row[0] in filesList and row[1] in filesList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the update image couples and corresponding labels\n",
    "with open(\"data/imagesgoogle_cleaned.csv\", 'w', newline = \"\") as myfile:\n",
    "    wr = csv.writer(myfile)\n",
    "    for row in newData:\n",
    "        wr.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation\n",
    "\n",
    "Increase the size of the dataset by:\n",
    "    1. Using transitivity: if img[i] wins on img[j] and img[j] wins on img[k], then we assume img[i] wins on img[k]\n",
    "    2. Mirroring images to increase 4x the size of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use transitivity to augment the dataset: if img[i] wins on img[j] and img[j] wins on img[k], then add a new entry in the dataset saying that img[i] wins on img[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/imagesgoogle_cleaned.csv\") as csv_file:\n",
    "    newData = [row for row in csv.reader(csv_file)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transitive_increase(dlist):\n",
    "    nC = []\n",
    "    tot = 0\n",
    "    t1=0\n",
    "    t2=0\n",
    "    for i in range(0, len(dlist)):\n",
    "        for j in range(i, len(dlist)):\n",
    "            # 4 rules to extend the dataset through transitivity\n",
    "            x,y = dlist[i], dlist[j]\n",
    "            if x[1] == y[0] and x[2] == y[2]:\n",
    "                nC.append([x[0],y[1],x[2]])\n",
    "            elif x[0] == y[1] and x[2] == y[2]:\n",
    "                nC.append([x[1],y[0], opposite[x[2]]])\n",
    "            elif x[0] == y[0] and x[2] == opposite[y[2]]:\n",
    "                nC.append([x[1],y[1],y[2]])\n",
    "            elif x[1] == y[1] and x[2] == opposite[y[2]]:\n",
    "                nC.append([x[0],y[0],x[2]])\n",
    "\n",
    "    return nC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(li):\n",
    "    li.sort()\n",
    "    return list(li for li,_ in itertools.groupby(li))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\noldLen = 0\\n\\nnC = transitive_increase(newData)\\naugmented_data = newData + nC \\naugmented_data = [l for l in augmented_data if l[2]!=\"equals\"] # Remove \"equals\" to prevent infinite loops\\n\\nwhile(len(augmented_data) >= oldLen):\\n    oldLen = len(augmented_data)\\n    nC = remove_duplicates(transitive_increase(nC))\\n    augmented_data = augmented_data + nC\\n    print(len(augmented_data))\\n\\ndata = newData+nC\\nprint(\"Data length with duplicates: \"+str(len(data)))\\n\\ndata = remove_duplicates(data)\\n\\nprint(\"Data length without duplicates: \"+str(len(data)))\\n'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = newData + transitive_increase(newData)\n",
    "data = remove_duplicates(data)\n",
    "\n",
    "print(len(data))\n",
    "\n",
    "# Repeat transitive increase as much as possible - CAREFUL ABOUT THIS! OUTLIERS IN DATASET MAKE IT IMPOSSIBLE TO REPEAT THIS PROCESS\n",
    "'''\n",
    "oldLen = 0\n",
    "\n",
    "nC = transitive_increase(newData)\n",
    "augmented_data = newData + nC \n",
    "augmented_data = [l for l in augmented_data if l[2]!=\"equals\"] # Remove \"equals\" to prevent infinite loops\n",
    "\n",
    "while(len(augmented_data) >= oldLen):\n",
    "    oldLen = len(augmented_data)\n",
    "    nC = remove_duplicates(transitive_increase(nC))\n",
    "    augmented_data = augmented_data + nC\n",
    "    print(len(augmented_data))\n",
    "\n",
    "data = newData+nC\n",
    "print(\"Data length with duplicates: \"+str(len(data)))\n",
    "\n",
    "data = remove_duplicates(data)\n",
    "\n",
    "print(\"Data length without duplicates: \"+str(len(data)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the update image couples and corresponding labels\n",
    "with open(\"data/imagesgoogle_cleaned.csv\", 'w', newline = \"\") as myfile:\n",
    "    wr = csv.writer(myfile)\n",
    "    for row in data:\n",
    "        wr.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mirror images and add all possible combinations of unmirrored + mirrored images to csv file (NM-NM, NM-M, M-NM, M-M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Except: .DS_S\n",
      "Except: .ipynb_checkpo\n"
     ]
    }
   ],
   "source": [
    "filesList = [f[:-4] for f in os.listdir(\"imagesgoogle_cleaned\")]\n",
    "\n",
    "for fn in filesList:\n",
    "    try:\n",
    "        img = cv2.imread(\"imagesgoogle_cleaned/\"+fn+\".jpg\")\n",
    "        img = cv2.flip(img, 1)\n",
    "        cv2.imwrite(\"imagesgoogle_cleaned/\"+fn+\"_mirror.jpg\", img, [int(cv2.IMWRITE_JPEG_QUALITY), 80])\n",
    "    except:\n",
    "        print(\"Except: \"+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the comparison and labeling data for mirrored images\n",
    "with open(\"data/imagesgoogle_cleaned.csv\") as csv_file:\n",
    "    newData = [row for row in csv.reader(csv_file)]\n",
    "    \n",
    "mirror_extended = []\n",
    "for d in newData:\n",
    "    mirror_extended.append(d)\n",
    "    mirror_extended.append([d[0]+\"_mirror\", d[1], d[2]])\n",
    "    mirror_extended.append([d[0], d[1]+\"_mirror\", d[2]])\n",
    "    mirror_extended.append([d[0]+\"_mirror\", d[1]+\"_mirror\", d[2]])\n",
    "    \n",
    "# Save the updated image couples and corresponding labels\n",
    "with open(\"data/imagesgoogle_augmented.csv\", 'w', newline = \"\") as myfile:\n",
    "    wr = csv.writer(myfile)\n",
    "    for row in mirror_extended:\n",
    "        wr.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset balancing\n",
    "\n",
    "Balance \"right\" and \"left\" winners by swapping some of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
